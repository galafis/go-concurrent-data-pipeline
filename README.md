# Concurrent Data Pipeline with Go

[![Go Report Card](https://goreportcard.com/badge/github.com/GabrielDemetriosLafis/go-concurrent-data-pipeline)](https://goreportcard.com/report/github.com/GabrielDemetriosLafis/go-concurrent-data-pipeline)
![Go](https://img.shields.io/badge/Go-00ADD8?style=for-the-badge&logo=go&logoColor=white)
![JSON](https://img.shields.io/badge/Data%20Format-JSON-000000?style=for-the-badge&logo=json&logoColor=white)
![Mermaid](https://img.shields.io/badge/Diagrams-Mermaid-orange?style=for-the-badge&logo=mermaid&logoColor=white)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)

---

## ğŸ‡§ğŸ‡· Pipeline de Dados Concorrente com Go

Este repositÃ³rio apresenta uma **pipeline de dados de alta performance e concorrÃªncia desenvolvida em Go**, projetada para processar grandes volumes de dados de forma eficiente e escalÃ¡vel. O foco Ã© em demonstrar como utilizar as capacidades de concorrÃªncia nativas do Go (goroutines e channels) para construir sistemas de processamento de dados robustos, tolerantes a falhas e com baixa latÃªncia. Ã‰ ideal para **engenheiros de dados, desenvolvedores de backend e arquitetos de sistemas** que buscam soluÃ§Ãµes eficientes para ingestÃ£o, transformaÃ§Ã£o e carregamento de dados em tempo real ou em lote.

### ğŸ¯ Objetivo

O principal objetivo deste projeto Ã© **fornecer exemplos prÃ¡ticos, cÃ³digo funcional e documentaÃ§Ã£o detalhada** sobre a construÃ§Ã£o de pipelines de dados concorrentes com Go. SerÃ£o abordados tÃ³picos como consumo de mensagens de filas (e.g., Kafka), processamento paralelo de dados, persistÃªncia em bancos de dados, tratamento de erros e monitoramento, tudo com foco em **performance, resiliÃªncia e manutenibilidade**, com Ãªnfase em **validaÃ§Ã£o de dados, transformaÃ§Ãµes complexas, tratamento de erros e coleta de mÃ©tricas**.

### âœ¨ Destaques

- **ConcorrÃªncia Nativa com Go**: UtilizaÃ§Ã£o de goroutines e channels para construir pipelines de dados altamente concorrentes e eficientes, permitindo o processamento paralelo de dados em vÃ¡rias etapas.
- **ValidaÃ§Ã£o de Dados e Tratamento de Erros**: ImplementaÃ§Ã£o de uma etapa de validaÃ§Ã£o (`validator`) que filtra dados invÃ¡lidos e um `errorHandler` dedicado para persistir e gerenciar registros com falha, garantindo a integridade da pipeline.
- **TransformaÃ§Ãµes de Dados Complexas**: A etapa de `transformer` demonstra como aplicar lÃ³gica de negÃ³cios mais sofisticada, como cÃ¡lculo de scores de anomalia, e lidar com diferentes tipos de erros de transformaÃ§Ã£o.
- **Coleta e SumarizaÃ§Ã£o de MÃ©tricas**: Um `metricsCollector` dedicado para monitorar o fluxo de dados, contando registros processados, erros e anomalias, fornecendo um sumÃ¡rio abrangente da performance da pipeline.
- **PersistÃªncia FlexÃ­vel**: Os `loader` e `errorHandler` persistem os dados processados e com erro em arquivos JSONL, demonstrando uma abordagem flexÃ­vel para armazenamento de resultados.
- **Escalabilidade Horizontal**: O design da pipeline permite fÃ¡cil escalabilidade, adicionando mais workers para as etapas de validaÃ§Ã£o e transformaÃ§Ã£o conforme a demanda.
- **CÃ³digo Profissional**: Exemplos de cÃ³digo bem estruturados, seguindo as melhores prÃ¡ticas da indÃºstria, com foco em clareza, eficiÃªncia e documentaÃ§Ã£o interna.
- **Testes IncluÃ­dos**: MÃ³dulos de cÃ³digo validados atravÃ©s de testes unitÃ¡rios e de integraÃ§Ã£o, garantindo a robustez e a confiabilidade das implementaÃ§Ãµes.

### ğŸš€ BenefÃ­cios do Go para Pipelines de Dados em AÃ§Ã£o

Go Ã© uma linguagem poderosa e eficiente para a construÃ§Ã£o de pipelines de dados concorrentes e de alta performance. Este projeto ilustra como esses benefÃ­cios sÃ£o explorados:

1.  **ConcorrÃªncia Simplificada e Eficaz:** Com goroutines e channels, Go torna a programaÃ§Ã£o concorrente muito mais fÃ¡cil e segura, permitindo a construÃ§Ã£o de um pipeline multi-estÃ¡gio (producer, validator, transformer, loader, errorHandler, metricsCollector) onde cada etapa opera de forma independente e paralela.

2.  **Performance Otimizada:** Compilado para cÃ³digo de mÃ¡quina, Go oferece performance prÃ³xima Ã  de C/C++, ideal para cargas de trabalho intensivas em CPU e I/O, como a geraÃ§Ã£o, validaÃ§Ã£o e transformaÃ§Ã£o de milhÃµes de registros de dados.

3.  **EficiÃªncia de Recursos:** Goroutines sÃ£o leves e o scheduler do Go Ã© otimizado para gerenciar milhares delas eficientemente, resultando em baixo consumo de memÃ³ria e CPU, mesmo ao lidar com um grande nÃºmero de registros e workers.

4.  **Tratamento de Erros Robusto:** O modelo de tratamento de erros explÃ­cito de Go Ã© fundamental para pipelines de dados, permitindo que a pipeline identifique e desvie registros invÃ¡lidos ou com falha para um `errorHandler` dedicado, sem interromper o fluxo principal.

5.  **Observabilidade Integrada:** A inclusÃ£o de um `metricsCollector` demonstra como Ã© fÃ¡cil integrar a coleta de mÃ©tricas diretamente na pipeline, fornecendo insights em tempo real sobre o volume de dados, erros e anomalias.

6.  **Modularidade e Manutenibilidade:** A estrutura baseada em funÃ§Ãµes e canais promove a modularidade, tornando cada etapa da pipeline um componente independente que pode ser facilmente testado, mantido e substituÃ­do.

---

## ğŸ‡¬ğŸ‡§ Concurrent Data Pipeline with Go

This repository presents a **high-performance and concurrent data pipeline developed in Go**, designed to process large volumes of data efficiently and scalably. The focus is on demonstrating how to use Go's native concurrency capabilities (goroutines and channels) to build robust, fault-tolerant, and low-latency data processing systems. It is ideal for **data engineers, backend developers, and system architects** seeking efficient solutions for real-time or batch data ingestion, transformation, and loading.

### ğŸ¯ Objective

The main objective of this project is to **provide practical examples, functional code, and detailed documentation** on building concurrent data pipelines with Go. Topics covered include consuming messages from queues (e.g., Kafka), parallel data processing, persistence in databases, error handling, and monitoring, all with a focus on **performance, resilience, and maintainability**, with an emphasis on **data validation, complex transformations, error handling, and metrics collection**.

### âœ¨ Highlights

- **Native Concurrency with Go**: Utilization of goroutines and channels to build highly concurrent and efficient data pipelines, allowing parallel data processing at various stages.
- **Data Validation and Error Handling**: Implementation of a validation stage (`validator`) that filters invalid data and a dedicated `errorHandler` to persist and manage failed records, ensuring pipeline integrity.
- **Complex Data Transformations**: The `transformer` stage demonstrates how to apply more sophisticated business logic, such as anomaly score calculation, and handle different types of transformation errors.
- **Metrics Collection and Summarization**: A dedicated `metricsCollector` to monitor data flow, counting processed records, errors, and anomalies, providing a comprehensive summary of pipeline performance.
- **Flexible Persistence**: The `loader` and `errorHandler` persist processed and erroneous data into JSONL files, demonstrating a flexible approach to result storage.
- **Horizontal Scalability**: The pipeline design allows for easy scalability, adding more workers for validation and transformation stages as demand increases.
- **Professional Code**: Well-structured code examples, following industry best practices, with a focus on clarity, efficiency, and internal documentation.
- **Tests Included**: Code modules validated through unit and integration tests, ensuring the robustness and reliability of the implementations.

### ğŸ“Š Visualization

![Go Data Pipeline Flow](diagrams/go_data_pipeline_flow.png)

*Diagrama ilustrativo da arquitetura da pipeline de dados concorrente em Go, destacando as etapas de processamento e a comunicaÃ§Ã£o entre elas.*


---

## ğŸ› ï¸ Tecnologias Utilizadas / Technologies Used

| Categoria         | Tecnologia      | DescriÃ§Ã£o                                                                 |
| :---------------- | :-------------- | :------------------------------------------------------------------------ |
| **Linguagem**     | Go              | Linguagem principal para desenvolvimento da pipeline de dados concorrente. |
| **ConcorrÃªncia**  | Goroutines, Channels | Primitivas nativas do Go para programaÃ§Ã£o concorrente e comunicaÃ§Ã£o segura. |
| **Formato de Dados** | JSONL           | Formato de arquivo para armazenamento de dados processados e com erro.    |
| **Testes**        | `testing`       | Pacote padrÃ£o do Go para escrita de testes unitÃ¡rios e de integraÃ§Ã£o.     |
| **Logging**       | `log`           | Pacote padrÃ£o do Go para registro de eventos e mensagens da pipeline.     |
| **DiagramaÃ§Ã£o**   | Mermaid         | Para criaÃ§Ã£o de diagramas de arquitetura e fluxo de dados no README.      |

---

## ğŸ“ Repository Structure

```
go-concurrent-data-pipeline/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/     # GitHub Actions CI/CD workflows
â”œâ”€â”€ src/               # Main application entry point (main.go)
â”œâ”€â”€ pkg/pipeline/      # Core pipeline implementation modules
â”‚   â”œâ”€â”€ types.go       # Data structures and type definitions
â”‚   â”œâ”€â”€ producer.go    # Data generation/ingestion stage
â”‚   â”œâ”€â”€ validator.go   # Data validation stage
â”‚   â”œâ”€â”€ transformer.go # Data transformation and enrichment stage
â”‚   â”œâ”€â”€ loader.go      # Data persistence stage
â”‚   â”œâ”€â”€ errorHandler.go # Error handling and logging stage
â”‚   â”œâ”€â”€ metricsCollector.go # Metrics aggregation stage
â”‚   â”œâ”€â”€ run.go         # Pipeline orchestration logic
â”‚   â””â”€â”€ pipeline_test.go # Unit tests for pipeline components
â”œâ”€â”€ tests/             # Integration tests
â”‚   â””â”€â”€ main_test.go   # End-to-end pipeline tests
â”œâ”€â”€ docs/              # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md # Detailed architecture documentation
â”‚   â””â”€â”€ CONTRIBUTING.md # Contribution guidelines
â”œâ”€â”€ config/            # Configuration files
â”‚   â”œâ”€â”€ config.example.yaml # Example configuration
â”‚   â””â”€â”€ placeholder.txt
â”œâ”€â”€ data/              # Sample data files for testing
â”‚   â”œâ”€â”€ sample_input.jsonl # Example input data
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ diagrams/          # Architecture diagrams
â”‚   â”œâ”€â”€ go_data_pipeline_flow.mmd # Mermaid diagram source
â”‚   â””â”€â”€ go_data_pipeline_flow.png # Rendered diagram
â”œâ”€â”€ images/            # Images for documentation
â”œâ”€â”€ logs/              # Log files directory (gitignored)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ .gitignore         # Git ignore rules
â”œâ”€â”€ go.mod             # Go module definition
â”œâ”€â”€ LICENSE            # MIT License
â””â”€â”€ README.md          # This file
```

---

## ğŸš€ Getting Started

### PrÃ©-requisitos

- Go 1.18 ou superior ([Baixar Go](https://go.dev/dl/))
- Git

### InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/GabrielDemetriosLafis/go-concurrent-data-pipeline.git
cd go-concurrent-data-pipeline

# Verifique a instalaÃ§Ã£o do Go
go version

# Execute os testes para validar a instalaÃ§Ã£o
go test ./... -v

# Compile o projeto
go build -o pipeline ./src/main.go

# Execute o pipeline
./pipeline
```

### ExecuÃ§Ã£o RÃ¡pida

```bash
# Execute diretamente sem compilar
go run src/main.go

# Execute com nÃºmero customizado de registros e workers
# (modifique os parÃ¢metros em src/main.go)
```

### Visualizando os Resultados

ApÃ³s executar o pipeline, vocÃª encontrarÃ¡:

```bash
# Dados processados com sucesso
cat processed_data.jsonl

# Registros que falharam na validaÃ§Ã£o/transformaÃ§Ã£o
cat failed_data.jsonl
```

### Exemplo de Uso AvanÃ§ado (Go)

O exemplo abaixo demonstra a execuÃ§Ã£o da pipeline de dados concorrente, utilizando o mÃ³dulo `pkg/pipeline` para orquestrar as etapas de geraÃ§Ã£o de registros, validaÃ§Ã£o, transformaÃ§Ã£o (com detecÃ§Ã£o de anomalias), carregamento para arquivos de saÃ­da e tratamento de erros. Um `metricsCollector` sumariza o desempenho da pipeline, fornecendo uma visÃ£o completa do fluxo de dados.

```go
package main

import (
	"fmt"
	"log"
	"os"
	"go-concurrent-data-pipeline/pkg/pipeline"
)

func main() {
	log.SetFlags(log.Ldate | log.Ltime | log.Lshortfile)
	fmt.Println("===========================================")
	fmt.Println("Go Concurrent Data Pipeline")
	fmt.Println("===========================================")

	// Limpar arquivos de saÃ­da anteriores
	_ = os.Remove("processed_data.jsonl")
	_ = os.Remove("failed_data.jsonl")

	// Executar a pipeline com 50 registros e 3 workers para validaÃ§Ã£o/transformaÃ§Ã£o
	// Os logs detalhados serÃ£o exibidos no console e as mÃ©tricas no final.
	metrics := pipeline.RunAdvancedPipeline(50, 3)

	fmt.Println("===========================================")
	fmt.Println("Pipeline completed!")
	fmt.Printf("Final Metrics: Processed=%d, Errors=%d, Anomalies=%d\n", 
		metrics.ProcessedCount, metrics.ErrorCount, metrics.AnomalyCount)
	fmt.Println("===========================================")

	// Opcional: Ler os arquivos de saÃ­da para verificar o conteÃºdo
	fmt.Println("\nConteÃºdo de processed_data.jsonl:")
	processedContent, err := os.ReadFile("processed_data.jsonl")
	if err == nil {
		fmt.Println(string(processedContent))
	} else {
		fmt.Println("  (Arquivo nÃ£o encontrado ou vazio)")
	}

	fmt.Println("\nConteÃºdo de failed_data.jsonl:")
	failedContent, err := os.ReadFile("failed_data.jsonl")
	if err == nil {
		fmt.Println(string(failedContent))
	} else {
		fmt.Println("  (Arquivo nÃ£o encontrado ou vazio)")
	}
}
```

### Executando os Testes

```bash
# Execute todos os testes
go test ./... -v

# Execute apenas testes unitÃ¡rios da pipeline
go test ./pkg/pipeline -v

# Execute apenas testes de integraÃ§Ã£o
go test ./tests -v

# Execute com cobertura de cÃ³digo
go test ./... -coverprofile=coverage.out
go tool cover -html=coverage.out

# Execute benchmarks
go test ./pkg/pipeline -bench=. -benchmem
```

### Exemplo de SaÃ­da

```
===========================================
Go Concurrent Data Pipeline
===========================================
2025/10/16 01:46:08 Producer: Iniciando produÃ§Ã£o de dados...
2025/10/16 01:46:08 Validator: Validando registro rec-0000
2025/10/16 01:46:08 Transformer: Transformando registro rec-0001
2025/10/16 01:46:08 Loader: Carregado rec-0001 (Anomaly: false)
...
2025/10/16 01:46:09 --- SumÃ¡rio da Pipeline ---
2025/10/16 01:46:09 Registros Processados com Sucesso: 41
2025/10/16 01:46:09 Registros com Erro: 9
2025/10/16 01:46:09 Registros AnÃ´malos: 8
2025/10/16 01:46:09 Valor Total Processado: 2137.08
2025/10/16 01:46:09 ---------------------------
===========================================
Pipeline completed!
Final Metrics: Processed=41, Errors=9, Anomalies=8
===========================================
```

---

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues, enviar pull requests ou sugerir melhorias.

Por favor, leia [CONTRIBUTING.md](docs/CONTRIBUTING.md) para detalhes sobre o processo de contribuiÃ§Ã£o e cÃ³digo de conduta.

### Como Contribuir

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [Arquitetura Detalhada](docs/ARCHITECTURE.md) - DecisÃµes de design e padrÃµes utilizados
- [Guia de ContribuiÃ§Ã£o](docs/CONTRIBUTING.md) - Como contribuir com o projeto
- [Dados de Exemplo](data/README.md) - InformaÃ§Ãµes sobre os dados de teste

---

## ğŸ§ª Testes e Qualidade

Este projeto mantÃ©m alta qualidade de cÃ³digo atravÃ©s de:

- âœ… **Testes UnitÃ¡rios** - Cobertura de componentes individuais
- âœ… **Testes de IntegraÃ§Ã£o** - ValidaÃ§Ã£o end-to-end da pipeline
- âœ… **Benchmarks** - MediÃ§Ã£o de performance
- âœ… **CI/CD** - GitHub Actions para testes automÃ¡ticos
- âœ… **Linting** - AnÃ¡lise estÃ¡tica de cÃ³digo com golangci-lint

[![Tests](https://github.com/GabrielDemetriosLafis/go-concurrent-data-pipeline/actions/workflows/go-test.yml/badge.svg)](https://github.com/GabrielDemetriosLafis/go-concurrent-data-pipeline/actions/workflows/go-test.yml)

---

## ğŸ“Š Performance

Resultados de benchmark em uma mÃ¡quina com 8 cores:

| Workers | Throughput (rec/s) | LatÃªncia MÃ©dia (ms) |
|---------|-------------------|---------------------|
| 1       | ~50               | 20                  |
| 2       | ~95               | 10.5                |
| 3       | ~140              | 7.1                 |
| 4       | ~180              | 5.5                 |
| 8       | ~300              | 3.3                 |

*Os resultados podem variar dependendo do hardware e da carga de trabalho.*

---

## ğŸ” Casos de Uso

Este projeto pode ser adaptado para diversos cenÃ¡rios:

1. **IoT Data Processing** - Processar streams de dados de sensores IoT
2. **Log Aggregation** - Agregar e processar logs de aplicaÃ§Ãµes
3. **ETL Pipelines** - Extract, Transform, Load de dados
4. **Real-time Analytics** - AnÃ¡lise de dados em tempo real
5. **Data Validation** - ValidaÃ§Ã£o em lote de grandes volumes de dados
6. **Anomaly Detection** - DetecÃ§Ã£o de anomalias em sÃ©ries temporais

---

## ğŸ› ï¸ Ferramentas e Recursos

### RecomendaÃ§Ãµes de Desenvolvimento

- **IDE**: VSCode com extensÃ£o Go, GoLand, ou Vim com vim-go
- **Debugging**: Delve debugger (`dlv`)
- **Profiling**: pprof para anÃ¡lise de performance
- **Monitoring**: Prometheus + Grafana (para produÃ§Ã£o)

### Recursos para Aprendizado

- [Go by Example](https://gobyexample.com/)
- [Effective Go](https://go.dev/doc/effective_go)
- [Go Concurrency Patterns](https://go.dev/blog/pipelines)
- [Advanced Go Concurrency Patterns](https://go.dev/blog/io2013-talk-concurrency)

---

## â“ FAQ

**P: Quantos workers devo usar?**  
R: Comece com o nÃºmero de CPUs disponÃ­veis. Ajuste baseado em profiling e mÃ©tricas.

**P: Como escalar para milhÃµes de registros?**  
R: Aumente o nÃºmero de workers e considere processar em batches. Para volumes muito grandes, considere distribuir em mÃºltiplas instÃ¢ncias.

**P: Posso usar com dados de fontes externas?**  
R: Sim! Modifique o Producer para ler de Kafka, databases, APIs, etc.

**P: Como adicionar persistÃªncia em banco de dados?**  
R: Modifique o Loader para escrever em PostgreSQL, MongoDB, etc., em vez de arquivos.

**P: Ã‰ adequado para produÃ§Ã£o?**  
R: O cÃ³digo demonstra padrÃµes de produÃ§Ã£o, mas adicione configuraÃ§Ã£o, monitoramento, e tratamento de erros mais robusto para uso em produÃ§Ã£o.

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

```
MIT License

Copyright (c) 2025 Gabriel Demetrios Lafis

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

---

## ğŸ‘¨â€ğŸ’» Autor

**Gabriel Demetrios Lafis**

- GitHub: [@GabrielDemetriosLafis](https://github.com/GabrielDemetriosLafis)
- LinkedIn: [Gabriel Demetrios Lafis](https://www.linkedin.com/in/gabriel-demetrios-lafis)

---

## ğŸ™ Agradecimentos

- Comunidade Go por excelentes recursos e documentaÃ§Ã£o
- Contribuidores que ajudaram a melhorar este projeto
- Todos que usam e fornecem feedback

---

## ğŸ“ˆ Status do Projeto

ğŸŸ¢ **Ativo e Mantido** - Issues e PRs sÃ£o bem-vindos!

**Ãšltima atualizaÃ§Ã£o:** Outubro 2025

**VersÃ£o:** 1.0.0

