# Concurrent Data Pipeline with Go

![Go](https://img.shields.io/badge/Go-00ADD8?style=for-the-badge&logo=go&logoColor=white)
![JSON](https://img.shields.io/badge/Data%20Format-JSON-000000?style=for-the-badge&logo=json&logoColor=white)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)

---

## ğŸ‡§ğŸ‡· Pipeline de Dados Concorrente com Go

Uma pipeline de dados concorrente escrita em Go, usando goroutines e channels para processar registros em paralelo. O projeto demonstra validaÃ§Ã£o, transformaÃ§Ã£o, detecÃ§Ã£o de anomalias e persistÃªncia de dados em formato JSONL.

### ğŸ¯ Objetivo

Demonstrar a construÃ§Ã£o de uma pipeline de dados concorrente em Go, cobrindo validaÃ§Ã£o de dados, transformaÃ§Ãµes, tratamento de erros e coleta de mÃ©tricas.

### âœ¨ Destaques

- **ConcorrÃªncia com goroutines e channels**: Pipeline multi-estÃ¡gio com producer, validator, transformer, loader, error handler e metrics collector rodando em paralelo.
- **ValidaÃ§Ã£o de dados**: Filtragem de registros invÃ¡lidos com roteamento para um error handler dedicado.
- **TransformaÃ§Ãµes com detecÃ§Ã£o de anomalias**: CÃ¡lculo de scores de anomalia e classificaÃ§Ã£o de registros.
- **Coleta de mÃ©tricas**: Contagem de registros processados, erros e anomalias ao longo da execuÃ§Ã£o.
- **PersistÃªncia em JSONL**: SaÃ­da de registros processados e com falha em arquivos JSONL.
- **Workers configurÃ¡veis**: NÃºmero de goroutines de validaÃ§Ã£o e transformaÃ§Ã£o ajustÃ¡vel.
- **Testes unitÃ¡rios e de integraÃ§Ã£o**: Cobertura das etapas individuais e da pipeline completa.

---

## ğŸ‡¬ğŸ‡§ Concurrent Data Pipeline with Go

A concurrent data pipeline written in Go, using goroutines and channels to process records in parallel. The project demonstrates validation, transformation, anomaly detection, and JSONL data persistence.

### ğŸ¯ Objective

Show how to build a concurrent data pipeline in Go, covering data validation, transformations, error handling, and metrics collection.

### âœ¨ Highlights

- **Concurrency with goroutines and channels**: Multi-stage pipeline with producer, validator, transformer, loader, error handler, and metrics collector running in parallel.
- **Data validation**: Invalid record filtering with routing to a dedicated error handler.
- **Transformations with anomaly detection**: Anomaly score calculation and record classification.
- **Metrics collection**: Counts of processed records, errors, and anomalies throughout execution.
- **JSONL persistence**: Output of processed and failed records to JSONL files.
- **Configurable workers**: Adjustable number of validation and transformation goroutines.
- **Unit and integration tests**: Coverage of individual stages and the full pipeline.

### ğŸ“Š Visualization

![Go Data Pipeline Flow](diagrams/go_data_pipeline_flow.png)

*Diagrama ilustrativo da arquitetura da pipeline de dados concorrente em Go, destacando as etapas de processamento e a comunicaÃ§Ã£o entre elas.*


---

## ğŸ› ï¸ Tecnologias Utilizadas / Technologies Used

| Categoria         | Tecnologia      | DescriÃ§Ã£o                                                                 |
| :---------------- | :-------------- | :------------------------------------------------------------------------ |
| **Linguagem**     | Go              | Linguagem principal para desenvolvimento da pipeline de dados concorrente. |
| **ConcorrÃªncia**  | Goroutines, Channels | Primitivas nativas do Go para programaÃ§Ã£o concorrente e comunicaÃ§Ã£o segura. |
| **Formato de Dados** | JSONL           | Formato de arquivo para armazenamento de dados processados e com erro.    |
| **Testes**        | `testing`       | Pacote padrÃ£o do Go para escrita de testes unitÃ¡rios e de integraÃ§Ã£o.     |
| **Logging**       | `log`           | Pacote padrÃ£o do Go para registro de eventos e mensagens da pipeline.     |
| **DiagramaÃ§Ã£o**   | Mermaid         | Para criaÃ§Ã£o de diagramas de arquitetura e fluxo de dados no README.      |

---

## ğŸ“ Repository Structure

```
go-concurrent-data-pipeline/
â”œâ”€â”€ src/               # Main application entry point (main.go)
â”œâ”€â”€ pkg/pipeline/      # Core pipeline implementation modules
â”‚   â”œâ”€â”€ types.go       # Data structures and type definitions
â”‚   â”œâ”€â”€ producer.go    # Data generation/ingestion stage
â”‚   â”œâ”€â”€ validator.go   # Data validation stage
â”‚   â”œâ”€â”€ transformer.go # Data transformation and enrichment stage
â”‚   â”œâ”€â”€ loader.go      # Data persistence stage
â”‚   â”œâ”€â”€ errorHandler.go # Error handling and logging stage
â”‚   â”œâ”€â”€ metricsCollector.go # Metrics aggregation stage
â”‚   â”œâ”€â”€ run.go         # Pipeline orchestration logic
â”‚   â””â”€â”€ pipeline_test.go # Unit tests for pipeline components
â”œâ”€â”€ tests/             # Integration tests
â”‚   â””â”€â”€ main_test.go   # End-to-end pipeline tests
â”œâ”€â”€ docs/              # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md # Detailed architecture documentation
â”‚   â””â”€â”€ CONTRIBUTING.md # Contribution guidelines
â”œâ”€â”€ config/            # Configuration files
â”‚   â””â”€â”€ config.example.yaml # Example configuration
â”œâ”€â”€ data/              # Sample data files for testing
â”‚   â”œâ”€â”€ sample_input.jsonl # Example input data
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ diagrams/          # Architecture diagrams
â”‚   â”œâ”€â”€ go_data_pipeline_flow.mmd # Mermaid diagram source
â”‚   â”œâ”€â”€ go_pipeline.mmd           # Simplified pipeline diagram
â”‚   â””â”€â”€ go_data_pipeline_flow.png # Rendered diagram
â”œâ”€â”€ images/            # Images for documentation
â”œâ”€â”€ logs/              # Log files directory (gitignored)
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ .gitignore         # Git ignore rules
â”œâ”€â”€ go.mod             # Go module definition
â”œâ”€â”€ LICENSE            # MIT License
â””â”€â”€ README.md          # This file
```

---

## ğŸš€ Getting Started

### PrÃ©-requisitos

- Go 1.18 ou superior ([Baixar Go](https://go.dev/dl/))
- Git

### InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/galafis/go-concurrent-data-pipeline.git
cd go-concurrent-data-pipeline

# Verifique a instalaÃ§Ã£o do Go
go version

# Execute os testes para validar a instalaÃ§Ã£o
go test ./... -v

# Compile o projeto
go build -o pipeline ./src/main.go

# Execute o pipeline
./pipeline
```

### ExecuÃ§Ã£o RÃ¡pida

```bash
# Execute diretamente sem compilar
go run src/main.go

# Execute com nÃºmero customizado de registros e workers
# (modifique os parÃ¢metros em src/main.go)
```

### Visualizando os Resultados

ApÃ³s executar o pipeline, vocÃª encontrarÃ¡:

```bash
# Dados processados com sucesso
cat processed_data.jsonl

# Registros que falharam na validaÃ§Ã£o/transformaÃ§Ã£o
cat failed_data.jsonl
```

### Exemplo de Uso AvanÃ§ado (Go)

O exemplo abaixo demonstra a execuÃ§Ã£o da pipeline de dados concorrente, utilizando o mÃ³dulo `pkg/pipeline` para orquestrar as etapas de geraÃ§Ã£o de registros, validaÃ§Ã£o, transformaÃ§Ã£o (com detecÃ§Ã£o de anomalias), carregamento para arquivos de saÃ­da e tratamento de erros. Um `metricsCollector` sumariza o desempenho da pipeline, fornecendo uma visÃ£o completa do fluxo de dados.

```go
package main

import (
	"fmt"
	"log"
	"os"
	"go-concurrent-data-pipeline/pkg/pipeline"
)

func main() {
	log.SetFlags(log.Ldate | log.Ltime | log.Lshortfile)
	fmt.Println("===========================================")
	fmt.Println("Go Concurrent Data Pipeline")
	fmt.Println("===========================================")

	// Limpar arquivos de saÃ­da anteriores
	_ = os.Remove("processed_data.jsonl")
	_ = os.Remove("failed_data.jsonl")

	// Executar a pipeline com 50 registros e 3 workers para validaÃ§Ã£o/transformaÃ§Ã£o
	// Os logs detalhados serÃ£o exibidos no console e as mÃ©tricas no final.
	metrics := pipeline.RunAdvancedPipeline(50, 3)

	fmt.Println("===========================================")
	fmt.Println("Pipeline completed!")
	fmt.Printf("Final Metrics: Processed=%d, Errors=%d, Anomalies=%d\n", 
		metrics.ProcessedCount, metrics.ErrorCount, metrics.AnomalyCount)
	fmt.Println("===========================================")

	// Opcional: Ler os arquivos de saÃ­da para verificar o conteÃºdo
	fmt.Println("\nConteÃºdo de processed_data.jsonl:")
	processedContent, err := os.ReadFile("processed_data.jsonl")
	if err == nil {
		fmt.Println(string(processedContent))
	} else {
		fmt.Println("  (Arquivo nÃ£o encontrado ou vazio)")
	}

	fmt.Println("\nConteÃºdo de failed_data.jsonl:")
	failedContent, err := os.ReadFile("failed_data.jsonl")
	if err == nil {
		fmt.Println(string(failedContent))
	} else {
		fmt.Println("  (Arquivo nÃ£o encontrado ou vazio)")
	}
}
```

### Executando os Testes

```bash
# Execute todos os testes
go test ./... -v

# Execute apenas testes unitÃ¡rios da pipeline
go test ./pkg/pipeline -v

# Execute apenas testes de integraÃ§Ã£o
go test ./tests -v

# Execute com cobertura de cÃ³digo
go test ./... -coverprofile=coverage.out
go tool cover -html=coverage.out

# Execute benchmarks
go test ./pkg/pipeline -bench=. -benchmem
```

### Exemplo de SaÃ­da

```
===========================================
Go Concurrent Data Pipeline
===========================================
2025/10/16 01:46:08 Producer: Iniciando produÃ§Ã£o de dados...
2025/10/16 01:46:08 Validator: Validando registro rec-0000
2025/10/16 01:46:08 Transformer: Transformando registro rec-0001
2025/10/16 01:46:08 Loader: Carregado rec-0001 (Anomaly: false)
...
2025/10/16 01:46:09 --- SumÃ¡rio da Pipeline ---
2025/10/16 01:46:09 Registros Processados com Sucesso: 41
2025/10/16 01:46:09 Registros com Erro: 9
2025/10/16 01:46:09 Registros AnÃ´malos: 8
2025/10/16 01:46:09 Valor Total Processado: 2137.08
2025/10/16 01:46:09 ---------------------------
===========================================
Pipeline completed!
Final Metrics: Processed=41, Errors=9, Anomalies=8
===========================================
```

---

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Sinta-se Ã  vontade para abrir issues, enviar pull requests ou sugerir melhorias.

Por favor, leia [CONTRIBUTING.md](docs/CONTRIBUTING.md) para detalhes sobre o processo de contribuiÃ§Ã£o e cÃ³digo de conduta.

### Como Contribuir

1. Fork o repositÃ³rio
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- [Arquitetura Detalhada](docs/ARCHITECTURE.md) - DecisÃµes de design e padrÃµes utilizados
- [Guia de ContribuiÃ§Ã£o](docs/CONTRIBUTING.md) - Como contribuir com o projeto
- [Dados de Exemplo](data/README.md) - InformaÃ§Ãµes sobre os dados de teste

---

## ğŸ§ª Testes e Qualidade

- **Testes UnitÃ¡rios** â€” Cobertura dos componentes individuais da pipeline
- **Testes de IntegraÃ§Ã£o** â€” ValidaÃ§Ã£o end-to-end da pipeline completa
- **Benchmarks** â€” Benchmarks para Producer e Validator disponÃ­veis em `pkg/pipeline/pipeline_test.go`

---

## ğŸ” Casos de Uso

Este projeto pode ser adaptado para diversos cenÃ¡rios:

1. **IoT Data Processing** - Processar streams de dados de sensores IoT
2. **Log Aggregation** - Agregar e processar logs de aplicaÃ§Ãµes
3. **ETL Pipelines** - Extract, Transform, Load de dados
4. **Real-time Analytics** - AnÃ¡lise de dados em tempo real
5. **Data Validation** - ValidaÃ§Ã£o em lote de grandes volumes de dados
6. **Anomaly Detection** - DetecÃ§Ã£o de anomalias em sÃ©ries temporais

---

## ğŸ› ï¸ Ferramentas e Recursos

### RecomendaÃ§Ãµes de Desenvolvimento

- **IDE**: VSCode com extensÃ£o Go, GoLand, ou Vim com vim-go
- **Debugging**: Delve debugger (`dlv`)
- **Profiling**: pprof para anÃ¡lise de performance
- **Monitoring**: Prometheus + Grafana (para produÃ§Ã£o)

### Recursos para Aprendizado

- [Go by Example](https://gobyexample.com/)
- [Effective Go](https://go.dev/doc/effective_go)
- [Go Concurrency Patterns](https://go.dev/blog/pipelines)
- [Advanced Go Concurrency Patterns](https://go.dev/blog/io2013-talk-concurrency)

---

## â“ FAQ

**P: Quantos workers devo usar?**  
R: Comece com o nÃºmero de CPUs disponÃ­veis. Ajuste baseado em profiling e mÃ©tricas.

**P: Como escalar para milhÃµes de registros?**  
R: Aumente o nÃºmero de workers e considere processar em batches. Para volumes muito grandes, considere distribuir em mÃºltiplas instÃ¢ncias.

**P: Posso usar com dados de fontes externas?**  
R: Sim! Modifique o Producer para ler de Kafka, databases, APIs, etc.

**P: Como adicionar persistÃªncia em banco de dados?**  
R: Modifique o Loader para escrever em PostgreSQL, MongoDB, etc., em vez de arquivos.

**P: Ã‰ adequado para produÃ§Ã£o?**  
R: O cÃ³digo demonstra padrÃµes de produÃ§Ã£o, mas adicione configuraÃ§Ã£o, monitoramento, e tratamento de erros mais robusto para uso em produÃ§Ã£o.

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

```
MIT License

Copyright (c) 2025 Gabriel Demetrios Lafis

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

---

## ğŸ‘¨â€ğŸ’» Autor

**Gabriel Demetrios Lafis**

- GitHub: [@galafis](https://github.com/galafis)
- LinkedIn: [Gabriel Demetrios Lafis](https://www.linkedin.com/in/gabriel-demetrios-lafis)

---

## ğŸ™ Agradecimentos

- Comunidade Go por excelentes recursos e documentaÃ§Ã£o
- Contribuidores que ajudaram a melhorar este projeto
- Todos que usam e fornecem feedback

---

## ğŸ“ˆ Status do Projeto

**Ãšltima atualizaÃ§Ã£o:** Outubro 2025

